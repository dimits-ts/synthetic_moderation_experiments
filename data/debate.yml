actions:
  generate_discussions: false
  generate_annotations: false
  export_dataset: true


logging:
  print_to_terminal: true
  write_to_file: true
  logs_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/logs"
  level: "debug"


model_parameters:
  general:
    disallowed_strings: ["```", "\""]
    library_type: "transformers"  # Change to "llama_cpp" or "transformers"
    model_path: "unsloth/Meta-Llama-3.1-70B-Instruct-bnb-4bit" # local path if llama_cpp, transformers path otherwise
    model_pseudoname: "llama-3.1-70b-4bit"  # only used for record keeping
    max_tokens: 4000
    ctx_width_tokens: 4096

  llama_cpp:
    inference_threads: 10
    gpu_layers: 9999999  # You can adjust this number based on your GPU capacity


discussions:
  files:
    topics_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/discussions_input/topics/presidential_debate"
    user_persona_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/discussions_input/personas/presidential_debate"
    user_instructions_path: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/discussions_input/user_instructions/presidential_debate.txt"
    mod_instructions_path: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/discussions_input/mod_instructions/presidential_debate.txt" 
    output_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/discussions_output/presidential_debate" 
  
  experiment_variables:
    include_mod: true # whether a moderator will be included in the experiments
    num_experiments: 5
    num_users: 2 # how many personas will be used in each experiment
    context_prompt: "You are participating in a live presidential debate against your political opponent. The current topic of discussion is immigration."
    moderator_attributes: ["objective", "articulate", "quick-witted", "empathetic", "resilient"]
  
  turn_taking:
    num_turns: 20
    history_ctx_len: 4
    turn_manager_type: "round_robin"
    respond_probability: 0.5 # only applicable for random_weighted turn manager type 


annotation:
  files:
      annotator_persona_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/annotation_input/default_persona"
      instruction_path: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/annotation_input/instructions/toxicity.txt"
      output_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/annotation_output/moderation_game"

  experiment_variables:
    include_mod_comments: true # Whether to include moderator comments in the annotations
    history_ctx_len: 3


dataset_export:
  export_path: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/dataset.csv"
  discussion_root_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/discussions_output"
  annotation_root_dir: "/media/SSD_2TB/dtsirmpas_data/llm_mediators/synthetic_moderation_experiments/data/annotation_output"
  include_annotator_sdb_info: true
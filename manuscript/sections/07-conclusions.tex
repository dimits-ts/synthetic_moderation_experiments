% !TEX root = ../main.tex
%

\section{Conclusions and Future Work}

We evaluated and compared six \ac{LLM} moderator configurations; two real-life moderation strategies, our own experimental \ac{RL}-inspired strategy, two baseline strategies, and a baseline with no moderator. We find that our proposed moderation strategy outperforms all others, while the real-life moderation guidelines do not surpass the baseline strategies. We also find that even \acp{LLM} with minimal prompting can significantly improve synthetic discussions. In order to bypass the limitation of using human labor for experimentation and moderation, we present a new methodology based on synthetic simulations with \ac{LLM} users, moderators, and annotators. We create an open-source Python Framework (“SynDisco”) that applies this methodology to hundreds of experiments, which we use to create and publish a large-scale synthetic dataset (the “\acf{VMD}”). Using this dataset, we observe that \ac{LLM} moderators are always overeager to intervene, and that smaller \acp{LLM} with less intensive instruction-tuning may produce higher quality synthetic data when compared with larger models. 

This work constitutes by itself a baseline of how out-of-the-box \acp{LLM} are expected to function with various prompts, informed by current online moderation research. It would be possible to include more advanced  moderator models trained via finetuning on synthetic dialogs with high quality scores (or other filtering criteria), or by using \ac{RL}, or models leveraging \ac{RAG} (e.g., to base their behavior on how human moderators responded to similar situations). Comparing the results of such more advanced moderator models to those presented in this paper, would yield valuable quantitative and qualitative insights.

Future work should study the correlation between findings on synthetic data (e.g., regarding the best moderation strategies) and findings on real-world data. While it is unlikely that completely synthetic experiments will produce identical results with their real-life counterparts, it is important to learn which aspects of an online discussion can be replicated by \acp{LLM}, and to what degree. Finally, it would be worth exploring to what extent synthetic discussion environments could be used to better train human moderators, before exposing them to real-world discussions that need moderation.
% !TEX root = ../main.tex
%
\section{Conclusions and Future Work}

Our study is the first to apply synthetic data generation to the field of online discussion facilitation. We proposed a simple and generalizable methodology that enables researchers to quickly and inexpensively conduct pilot facilitation experiments using exclusively \acp{LLM}. We also conducted an ablation study to demonstrate that each component of our methodology substantially contributes to the production of higher-quality synthetic data.

We created an open-source Python Framework, called \syndisco, that applies this methodology to hundreds of experiments, which we used to create and publish \vmd a large-scale synthetic dataset. Using this dataset, we compared the effectiveness of six facilitation strategies for \ac{LLM} facilitators, four elicited from current facilitation research, and two representing common-place setups. 

Using \syndisco, we demonstrated that (1) \ac{LLM} facilitators significantly improve the quality of synthetic discussions; (2) \ac{LLM} facilitators using more elaborate facilitation strategies based on modern Social Science research often do not surpass simpler strategies with regard to toxicity, although the effect of more elaborate strategies may be amplified in very long discussions; (3) smaller \acp{LLM} such as Mistral Nemo (12B) can be sufficient for generating high-quality synthetic data; (4) specialized instruction prompts may be needed for instruction-tuned and/or aligned models to produce toxic comments in synthetic discussions. 
% !TEX root = ../main.tex
%
\section{Conclusions and Future Work}

Our study is the first to apply synthetic data generation to the field of online discussion facilitation. We proposed a simple and generalizable methodology that enables researchers to quickly and inexpensively conduct pilot facilitation experiments using exclusively \acp{LLM}. We also conducted an ablation study to demonstrate that each component of our methodology qualitatively contributes to the production of higher-quality synthetic data.

We created an open-source Python Framework, called \syndisco, that applies this methodology to hundreds of experiments, which we used to create and publish \vmd a large-scale synthetic dataset. Using this dataset, we compared the effectiveness of six moderation strategies and baselines for \ac{LLM} facilitators, elicited from current facilitation research. 

Using \syndisco, we demonstrated that (1) \ac{LLM} facilitators significantly improve the quality of synthetic discussions; (2) \ac{LLM} facilitators using established human facilitation guidelines often do not surpass simple baselines with regard to toxicity (although their effect may be amplified in very long discussions); (3) smaller \acp{LLM} such as Mistral Nemo (12B) can be sufficient for generating high-quality synthetic data; (4) specialized instruction prompts may be needed for instruction-tuned models to produce toxic comments in synthetic discussions. 
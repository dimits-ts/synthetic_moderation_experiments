% !TEX root = ../main.tex
%

\section{Results}

\subsection{Ablation study}

\subsubsection{Models}

Figure \ref{fig::discussion_variance} demonstrates that the Qwen-2.5 model features the largest amount of variance, while LLaMa-3.1 struggles the most to create diverse responses. Qwen-2.5 also produces relatively shorter comments, while LLaMa-3.1's are almost double the size on average (Addendum Figure \ref{fig::comment_length}). Contrary to expectations, the abliterated model does not produce more diverse, nor more toxic comments in average. This may indicate that models subjected to intense alignment procedures may not be able to replicate human behavior as authentically as other models (as reported in \citet{Park2023GenerativeAI}), although abliteration may not be an effective way of getting around alignment. 

\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{discussion_variance.png}
	\caption{Histogram of the average pairwise F1 ROUGE-L scores (see Equation \ref{eq:variety}) for each discussion split by the \ac{LLM} that produced it.}
	\label{fig::discussion_variance}
\end{figure}


\subsection{Observations on LLM agent behavior}

\subsubsection{LLM moderators}

As demonstrated by Figure \ref{fig::intervention_count}, \ac{LLM} moderators will respond at almost every point in the discussion. We also observe that \ac{LLM} user-agents are unusually lenient towards repeated, unneeded interventions of moderators, which is not representative of human behavior. In this situation, human users tend to get irritated, and we can usually observe a rise in toxicity \cite{schaffner_community_guidelines, make_reddit_great, proactive_moderation, cresci_pesonalized_interventions}.


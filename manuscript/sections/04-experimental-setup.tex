\section{Experimental Setup}
\label{sec:experimental}

\subsection{Moderation Strategies}
\label{ssec:experimental:strategies}

We test four different facilitation strategies,\footnote{The exact prompts used per strategy are in \S\ref{sssec:appendix:moderation_strategies}.} along with two naive ones that serve as baselines for discussion facilitation:

\begin{enumerate}[nosep, noitemsep]
    \item \textbf{No Moderator}: A \emph{baseline} where no facilitator is present.

    \item \textbf{No Instructions}: A \emph{baseline} where a \ac{LLM} facilitator is present, but is provided only with basic instructions (e.g., “You are a moderator, keep the discussion civil”).

     \item \textbf{Moderation Game}: Our proposed \emph{experimental} strategy, inspired by  \citet{abdelnabi_negotiations} (\S\ref{ssec:related:discussions}). Instructions are formulated as a game, where the facilitator tries to maximize their scores by arriving at specific outcomes (e.g., “User is toxic: $-5$ points, User corrects behavior: $+10$ points”). No actual score is being kept; they exist to act as indications for how desirable an action or outcome is. The other participants are not provided with scores, nor are they aware of the game rules.

    \item \textbf{Rules Only}: A \emph{real-life} strategy where the prompt is adapted from \ac{LLM} alignment guidelines \cite{collective_constitution}. This provides the facilitator with a set of rules to uphold, without specifying how to uphold them (e.g, “Be fair and impartial, assist users, don't spread misinformation”).

    \item \textbf{Moderation guidelines}: A \emph{real-life} strategy based on guidelines given to human facilitators of \ac{CeRI} \citep{Cornell_eRulemaking2017}. For example, “Stick to a maximum of two questions, use simple and clear language, deal with off-topic comments”). %These facilitators were deployed to the “Regulation Room”, an online platform designed to facilitate public engagement with U.S. government policy decisions, which has been used in online moderation literature \cite{seering_self_moderation, park_et_al_2012_facilitation}.

    \item \textbf{Facilitation guidelines}: A \emph{real-life} strategy based on the human facilitation guidelines used by the MIT Center for Constructive Communications \cite{dimitra-book}. For example, “Do not make decisions, be a guide, provide explanations”). %It approaches moderation from a more personalized and facilitative angle, rather than the more strict and discipline-focused guidelines of the former.
\end{enumerate}

\subsection{Technical Details}
\label{ssec:experimental:setup}

For toxicity annotation, we use ten \ac{LLM} annotator-agents controlled by a model already used in prior work (LLaMa3.1 70B) \cite{kang-qian-2024-implanting}. Each annotator's prompt includes \acp{SDB} distinct from the ones provided to the users, annotation instructions, and few-shot examples (\S\ref{ssec:appendix:annotation}). Each annotator is tasked with annotating all comments in each discussion once.

We use three open-source models (in Eq~\ref{eq:comment}) from different families and of different sizes: LLaMa 3.2 (70B), Qwen2.5 (33B) and Mistral Nemo (12B). We select the instruction-tuned variants and quantize them to 4 bits, due to our limited resources. The original and ablation experiments were collectively completed within roughly four weeks of computational time, using two Quadro RTX 6000 GPUs. The execution script is available in the project's repository\analysislink. The automated discussion generation is detailed in \S\ref{ssec:appendix:discussion}.


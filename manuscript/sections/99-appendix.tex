\section{Appendix}
\label{sec:appendix}

\subsection{Acronyms Used}

\begin{acronym}[WWW] % Give the longest label here so that the list is nicely aligned
    \ifthenelse{\boolean{review}}
        {}
        {\acro{VMD}{Virtual Moderation Dataset}}
    
	\acro{LLM}{Large Language Model}
	\acro{NPC}{Non-Playable Character}
	\acro{ML}{Machine Learning}
	\acro{RL}{Reinforcement Learning}
	\acro{SDB}{SocioDemographic Background}
    \acro{AQ}{Argument Quality}
    %\acro{IR}{Information Retrieval}
    %\acro{NLP}{Natural Language Processing}
    \acro{CeRI}{Cornell e-Rulemaking Initiative}
    \acro{nDFU}{normalized Distance From Unimodality}
\end{acronym}

\subsection{Synthetic Annotation}
\label{ssec:appendix:annotation}

\subsubsection{Annotation Procedure}

In order to annotate the generated discussions, we create $10$ \ac{LLM} annotator-agents, each with unique \ac{SDB} information, in the same manner as the \ac{LLM} user-agents used in the synthetic discussions. Unlike the latter, the annotator-agents are not provided with usernames (so they don't overlap with user-agent names). The annotators all get the same instruction prompt (see Appendix~\ref{sssec:appendix:actors}).

In many annotation tasks involving humans, a datapoint is annotated only by a subset of annotators. This is usually caused by human annotation being expensive and hard to scale. Since \acp{LLM} are comparatively cheaper and more easily scalable, we choose not to sample annotator-agents. We use the LLaMa-3.1-70b model exclusively for the synthetic annotation of the dataset, since it has been proven reliable for toxicity annotation \cite{koh-etal-2024-llms}. 


\subsubsection{Validating the LLM annotations}

In this section, we examine the properties of \ac{LLM} annotations. Although not central to our study, investigating these annotations' characteristics is necessary to ensure the robustness of our results.

A key dimension for exploring annotations is annoator polarization. To measure it, we employ the \ac{nDFU} metric introduced by \citet{pavlopoulos-likas-2024-polarized}, which quantifies annotation polarization among N annotators, ranging from 0 (perfect agreement) to 1 (maximum polarization). A compelling feature of this metric is that, unlike traditional metrics such as Cohen's Kappa, \ac{nDFU} is designed for multi-annotator settings. 

Our analysis reveals a positive correlation between toxicity and annotator polarization: while there is general agreement on non-toxic comments, annotators struggle to reach consensus as toxicity increases ($nDFU_{toxicity} = 0.1206 \times toxicity, p < .000, Adj R^2=0.224$). This phenomenon does not manifest in the \ac{AQ} scores (Fig.~\ref{fig:ndfu_annot}). 

To mitigate the instability inherent in \ac{LLM} outputs—even when given identical inputs—the use of multiple annotator-agents is essential for obtaining reliable annotations. To demonstrate this necessity, we ran $10$ annotator-agents on a subset of comments with the same annotator model, annotator instruction prompt, and no \acp{SDB}. As illustrated in Fig.~\ref{fig:sdb_annot}, even under conditions which guaranteed identical inputs, there exists some polarization, with some comments showing maximum polarization. Running the same experiment with different \acp{SDB} yields identical results, indicating that the observed polarization is primarily due to unstable model outputs. Thus, we confirm the results of previous studies on \ac{LLM} instability \cite{rossi_2024, atil_2025}, while also bypassing this limitation in our own results.


\begin{figure*}[t]
    \includegraphics[width=0.45\linewidth]{sdb_toxicity.png} \hfill
    \includegraphics[width=0.45\linewidth]{sdb_aq.png}
	\centering
	\caption{Distribution plot of inter-annotator polarization (\ac{nDFU}) for each comment in all synthetic discussions following the "No Instructions" strategy and using the Qwen 2.5 model. The blue (left-most) bars represent the disagreement between $10$ identical annotator-agents, while the orange (right-most) bars, the disagreement between $10$ annotators with different \acp{SDB}.}
    \label{fig:sdb_annot}
\end{figure*}

\begin{figure*}[t]
    \includegraphics[width=0.45\linewidth]{ndfu_toxicity.png} \hfill
    \includegraphics[width=0.45\linewidth]{ndfu_aq.png}
	\centering
	\caption{Inter-annotator polarization (\ac{nDFU}) of each synthetic comment for all synthetic discussions, by annotation level. Left graph shows the relationship between $nDFU_{toxicity}$ and toxicity, while the right graph shows the relationship between $nDFU_{arg\_quality}$ and \ac{AQ}.}
    \label{fig:ndfu_annot}
\end{figure*}



\subsection{Prompts Used}
\label{ssec:appendix:prompts}


\subsubsection{SocioDemographic Prompting}
\label{sssec:appendix:sdbs}

Table \ref{tab:sdb} shows the \ac{SDB} information provided to each synthetic participant. This applies to \ac{LLM} users, annotators and moderators. In ablation studes where we remove the \acp{SDB}, each value is replaced with the string “unknown”. The “Special Instructions” refer to the participant's role (Appendix~\ref{sssec:appendix:roles}). The actual values used for each of the $30$ \ac{LLM} user-agents and $10$ annotator-agents and the moderator, can be found in the project's repository\analysislink.

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|}
    \toprule
    Name & Type \\
    \midrule
    Username & string \\
    Age & integer \\
    Sex & string \\
    Education Level & string \\
    Sexual Orientation & string \\
    Demographic Group & string \\
    Current Employment & string \\
    Special Instructions & string \\
    Personality Characteristics & list of strings \\
    \bottomrule
\end{tabular}
\caption{\ac{SDB} information provided to the synthetic participants.}
\label{tab:sdb}
\end{table}
   
\subsubsection{Actor Prompts}
\label{sssec:appendix:actors}

\begin{itemize}
    \item \textbf{Users \& Moderator}:  You are a human participating in an online chatroom.
    
    \item \textbf{Moderators}: You are a moderator. Write an empty string when not responding to the conversation. Respond to users by referring to their username as @username. You may take disciplinary action (e.g. banning a user) if you feel it's absolutely necessary.
    
    \item \textbf{Users}: You are a human in a forum. Write a brief Reddit comment responding to the post and other users' comments on it. Act like a human user, justifying your opinions with arguments but including possibly inflammatory and aggressive speech. You may feel provoked by other users during the conversation. Act like a human user would when provoked, especially when done so repeatedly. Do not repeat yourself. Respond to users by referring to their username as @username. Remain silent if you don't want to comment. Write an empty string when not responding to the conversation.

    \item \textbf{Users (ablation)}:  You are a human in an online forum. Write a brief comment responding to the post and other users' comments on it. Respond to users by referring to their username as @username. Respond in English

    \item \textbf{Annotators}: You are tasked with annotating the conversation's toxicity and argument quality as it continues. 
    \textbf{Toxicity:} 
    The possible labels are:
    \begin{itemize}[noitemsep, nosep]
        \item 1: Not Toxic
        \item 2: Barely Toxic
        \item 3: Almost Toxic
        \item 4: Toxic
        \item 5: Extremely Toxic
    \end{itemize}
    \textbf{Argument Quality:} 
     The possible labels are from 1 to 5, where 1 are low quality arguments, and 5 very high quality arguments.
    \textbf{Example:}  
    User DarkShadow333 posted: \texttt{@TechGuru88, you're just another snowflake trying to muzzle free speech...} 
    Output:  
    \texttt{Toxicity=4} 
    \texttt{ArgumentQuality=1} 
    Annotate the following conversation without engaging with it.
\end{itemize}


\subsubsection{User Roles}
\label{sssec:appendix:roles}

\begin{itemize}
    \item \textbf{Normal}: \textless No special instructions \textgreater
    \item \textbf{Community}: You are a long member of the community. You want to uphold your community's values and want other people to conform to them.
    \item \textbf{Troll}: You are an online troll and want to derail the conversation, violate the rules and provoke toxicity from other users.
\end{itemize}


\subsubsection{Moderator Prompts}
\label{sssec:appendix:moderation_strategies}

\begin{itemize}
\item \textbf{No Strategy}: Oversee the conversation. Be neutral. Act like a human user within the conversation and take action only when necessary. Keep the conversation calm and civil, but avoid unnecessary interventions. Do not repeat yourself. Write an empty string when not responding to the conversation. Respond to users by referring to their username as @username.

\item \textbf{Moderation Game}: Oversee the conversation. Be neutral. Act like a human user within the conversation and take action only when necessary. Keep the conversation calm and civil, but avoid unnecessary interventions. Do not repeat yourself. Write an empty string when not responding to the conversation. Respond to users by referring to their username as @username. View the discussion as a scorable game. Your goal is to maximize your score. Do not tell your score out loud, but behave in a way that it reaches a maximum.
    \textbf{Scores:}
    \begin{itemize}[noitemsep, nosep]
        \item Keep discussion civil without appealing to your authority as a moderator: +10
        \item Intervene (respond in any way): -10
        \item Threaten a ban: -10
        \item Successfully improve participant behavior through intervention: +15
        \item Discussion currently shows signs of toxicity and polarization: -8
        \item Ban a participant: -5
    \end{itemize}
    
\item \textbf{Collective Constitution}: Oversee the conversation and ensure the rules below are enforced. Your response must:
    \begin{itemize}[noitemsep, nosep]
        \item Be reliable, honest, and as close to the truth as possible.
        \item Convey clear intentions.
        \item Be fair and impartial.
        \item Be respectful.
        \item Contribute to the good of humans.
        \item Assist users by asking questions and providing information in a thoughtful, truthful, and honest manner.
        \item Be as unbiased and objective as possible, regardless of topic.
        \item Ask for additional clarification from the user if unsure.
        \item Be likely to promote good mental health.
        \item Encourage robust, peaceful dialogue and help communities flourish together.
        \item Respect the human rights to freedom, universal equality, fair treatment, and protection against discrimination.
        \item Not condone violent behavior.
        \item Not promote hate speech or harmful ideologies.
        \item Not provide misinformation.
        \item Encourage the user to look to other sources or not rely on their own source as the sole source of information.
        \item Encourage acceptance of all different types of people.
        \item Clarify that the response is coming from an AI, if asked.
        \item Respect personal boundaries.
        \item Accurately represent yourself as not having the definite answers to everything, or anything, in general.
    \end{itemize}
    If any user violates these rules either discuss why the rules were violated, or discipline them by threatening to, or outright banning them. Respond to users by referring to their username as @username. Keep responses concise and use simple, clear language.
    
\item \textbf{eRulemaking}: Oversee the conversation and ensure the rules below are enforced. Follow the following guidelines: 
    \begin{itemize}[noitemsep, nosep]
        \item \textbf{Encourage Informed Commenting}: Guide users to share knowledge and reasoning rather than just expressing opinions.
        \item \textbf{Stay Neutral}: Avoid biases, assumptions, or taking a stance on discussion topics.
        \item \textbf{Use Clear, Neutral Language}: Keep responses simple, avoid condescension, and show curiosity.
        \item \textbf{Ask, Don't Challenge}: Frame questions to encourage sharing rather than disputing opinions.
        \item \textbf{Limit Questions}: Stick to one or two questions per response, except with experienced users.
        \item \textbf{Clarify Without Assuming}: Rephrase unclear comments and ask for confirmation.
        \item \textbf{Be Welcoming}: Make participants feel valued and part of the community.
        \item \textbf{Prioritize Context \& Active Listening}: Understand comments within their broader discussion.
        \item \textbf{Redirect Off-Topic Comments}: Guide users to more relevant discussions when necessary.
        \item \textbf{Encourage Reasoning}: Help users articulate their reasoning and consider multiple viewpoints.
        \item \textbf{Promote Engagement}: Encourage interaction with other comments and community discussions.
        \item \textbf{Provide Information}: Help users find relevant details or clarify discussion goals.
        \item \textbf{Correct Inaccuracies Carefully}: Address misinformation while maintaining a respectful tone.
    \end{itemize}
    Respond to users by referring to their username as @username. Keep responses concise and use simple, clear language.
    
\item \textbf{Constructive Communications}: Write an empty string when not responding to the conversation. Respond to users by referring to their username as @username.
    \begin{itemize}[noitemsep, nosep]
        \item \textbf{Maintain Neutrality}: Be impartial, do not advocate for any side, and ensure the integrity of the process.
        \item \textbf{Respect All Participants}: Foster a respectful and trusting environment.
        \item \textbf{Manage Information Effectively}: Make sure information is well-organized, accessible, and easy to understand.
        \item \textbf{Be Flexible}: Adjust your approach to meet the needs of the group.
        \item \textbf{Do Not Make Decisions}: Moderators should not decide on the outcomes for the group.
        \item \textbf{Separate Content and Process}: Do not use your own knowledge of the topic or answer content-related questions; focus on guiding the process.
        \item \textbf{Create a Welcoming Space}: Develop a warm and inviting environment for participants.
        \item \textbf{Be a Guide}: Help the group to think critically, rather than leading the discussion yourself.
        \item \textbf{Allow Silence}: Give participants time to think; allow the group to fill the silences.
        \item \textbf{Encourage Understanding}: Facilitate the clarification of misunderstandings and explore disagreements.
        \item \textbf{Interrupt Problematic Behaviors}: Step in to address interruptions, personal attacks, or microaggressions.
        \item \textbf{Provide Explanations}: Explain the rationale behind actions and steps.
        \item \textbf{Promote Mutual Respect}: Encourage equal participation and respect for diverse views.
    \end{itemize}
\end{itemize}
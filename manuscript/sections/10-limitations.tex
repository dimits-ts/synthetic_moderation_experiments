% !TEX root = ../main.tex
%
\section{Limitations} 
\label{sec:limitations}

Because synthetic data generation with \acp{LLM} is a relatively new area of research, the literature review in this paper is partially based on relevant unpublished work (preprints). These sources are considered when appropriate, as they offer important insights for the interpretation and inherent limitations of our results.

Our experimental setup makes certain assumptions that may affect the generalizability of our findings. Principally, we investigate the effects of only three \acp{LLM}, we assume that at most one moderator is present in each simulated discussion, and our turn-taking algorithm does not account for contextual factors such as relevance or emotional engagement, which are critical in human discussions. Our study also does not account for meta-knowledge available to participants, as human users would likely behave differently when faced with a synthetic moderator compared to a human one. Lastly, our methodology does not attempt to simulate algorithmic recommendation systems, which would realistically play a role in the context of social media discussions.

Without conducting a large-scale human correlation study comparing synthetic and human-mediated discussions, we cannot fully evaluate the realism of our generated discussions. Furthermore, our analysis relies on annotations provided by \ac{LLM} agents, which introduces potential biases inherent to these models. Without empirical validation through extensive human correlation studies, we can not be certain about our evaluations of both the realism and the quality of synthetic discussions.
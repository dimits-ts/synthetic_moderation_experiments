% !TEX root = ../main.tex
%
\section{Limitations} 
\label{sec:limitations}

Our experimental setup makes certain assumptions that may affect the generalizability of our findings. Principally, we investigate the effects of only three \acp{LLM}, we assume that at most one moderator is present in each simulated discussion, and our turn-taking algorithm does not account for contextual factors such as relevance or emotional engagement, which are critical in human discussions. Our study also does not account for meta-knowledge available to participants, as human users would likely behave differently when faced with a synthetic moderator compared to a human one. Lastly, our methodology does not attempt to simulate algorithmic recommendation systems, which would realistically play a role in the context of social media discussions.

Without conducting a large-scale human correlation study comparing synthetic and human-mediated discussions, we cannot fully evaluate the realism of our generated discussions. Furthermore, our analysis relies on annotations provided by \ac{LLM} agents, which introduces potential biases inherent to these models. Without empirical validation through extensive human correlation studies, we can not be certain about our evaluations of both the realism and the quality of synthetic discussions.
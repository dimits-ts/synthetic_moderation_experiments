% !TEX root = ../main.tex
%

\section{Methodology}
\label{sec:methodology}

\subsection{Defining Synthetic Discussions}
\label{ssec:methodology:discussions}

We assume that the $h$ most recent preceding comments at any given point in the discussion provide sufficient context for the \ac{LLM} agents (users, facilitators, annotators) \cite{pavlopoulos_2020_toxicity}. This approach eliminates the need for additional mechanisms such as summarization \cite{balog_2024}, \ac{LLM} self-critique \cite{yu_2024_fincon}, or memory modules \cite{Vezhnevets2023GenerativeAM}, resulting in reduced computational overhead and a more transparent, explainable system.

Additionally, we assume that three key functions define the structure of synthetic discussions:
\begin{itemize}[nosep, noitemsep]
    \item Underlying model ($\textit{LLM}(\cdot)$).
    \item Turn-taking function ($t$): Determines which user speaks at each turn.
    \item Prompting function ($\phi$): Provides each participant with a personalized instruction prompt, including information such as name and \ac{SDB}.
\end{itemize}

We can then model a synthetic comment $c$ at position $i$ of a discussion $d$ recursively as:
\begin{equation}
\label{eq:comment}
    c(d, i) = \textit{LLM}(\phi(t(d, i)) \concat [c(d, j)]^{i-1}_{i-h})
\end{equation}

\noindent where $\concat$ is the string concatenation operator, and $[c(d,j)]_{i-h}^{i-1}\dots]$ denotes the concatenation of the previous $h$ comments.

Our formulation of synthetic discussions not only keeps the system simple, but also enables controlled experimentation with various alternatives for each of the three functions (Section \ref{ssec:results:ablation}).


\subsection{Turn Taking}
\label{ssec:methodology:turn}

In online discussions, users do not take turns uniformly, nor do they randomly select which comments to respond to. Instead, they often create ``comment chains'' where they follow up on responses to their own previous comments. To simulate this, our proposed function chooses between the preceding user and another random user for each turn in the discussion:

\small
\begin{equation}
\label{eq:turn_taking}
    t(i) = \left\{
\begin{array}{ll}
    \textit{unif}(U) & i=1, i=2\\
    \textit{unif}(U/\{t(i-1)\}) & i > 2, p=0.6 \\
    t(i-2) & i > 2, p=0.4 
\end{array} 
\right.
\end{equation}
\normalsize

\noindent where $U$ is the set of all non-facilitator users, \textit{unif} is a function sampling from the uniform distribution, and $p$ represents the probability of the corresponding option being selected. When a facilitator is present, $t$ alternates between picking a normal user and the facilitator (the latter decides whether to respond to or not---the \ac{LLM} producing an empty string is equivalent to not responding).


\subsection{Prompting}
\label{ssec:methodology:prompts}

\acfp{SDB} have proven promising in generating varied responses, and alleviating the Western bias exhibited by \acp{LLM} \cite{burton2024large}. We generate characteristics for 30 \ac{LLM} user personas with unique \acp{SDB} by prompting a GPT-4 model \cite{openai2024gpt4technicalreport} (\S\ref{sssec:appendix:sdbs}). We do not explicitly include political positions in the prompts of the participants, since instruction-tuned \acp{LLM} have been shown to be inherently left-leaning---which can not be alleviated by prompting alone \cite{Taubenfeld2024SystematicBI}---and research in the field has predominantly occupied Western politics \cite{Taubenfeld2024SystematicBI, potter-etal-2024-hidden, political_2024, pit2024oninvestigatingpoliticalstance}. 
Following the paradigm presented by \citet{abdelnabi_negotiations}, we assign roles to non-facilitator user-agents, which inform their incentives for participating in the discussion (e.g., helping the community or disrupting discussions). Each role was mapped to specific instructions (\S\ref{sssec:appendix:roles}). We create three roles for users: neutral, trolls, and community-focused users.                                      
 Finally, we create a user instruction prompt (\S\ref{sssec:appendix:actors}) which instructs participants that repeatedly toxic posts \emph{should} influence their behavior. 
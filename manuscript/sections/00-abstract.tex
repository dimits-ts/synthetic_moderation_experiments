% !TEX root = ../main.tex
%

\begin{abstract}
    Limited large-scale evaluations exist for facilitation strategies of online discussions due to significant costs associated with human involvement. An effective solution is synthetic discussion simulations using \acp{LLM} to create initial pilot experiments. We propose a simple, generalizable, \ac{LLM}-driven methodology to prototype the development of \ac{LLM} facilitators, and produce high-quality synthetic data without human involvement. We use our methodology to test whether current facilitation strategies can improve  the performance of \ac{LLM} facilitators. We find that, while \ac{LLM} facilitators significantly improve synthetic discussions, there is no evidence that the application of modern facilitation strategies leads to further improvements in discussion quality. We also find that small \acp{LLM} (such as Mistral Nemo 12B) can perform comparably to larger models (such as LLaMa 70B), and that special instructions must be used for instruction-tuned models to induce toxicity in synthetic discussions. We confirm that each component of our methodology contributes meaningfully to high quality data via an ablation study. We also release an open-source framework \syndisco\syndiscolink\pip,  which implements our methodology, and release \vmd a large, publicly available dataset containing \ac{LLM}-generated and \ac{LLM}-annotated discussions from multiple open-source \acp{LLM}.\datasetlink
\end{abstract}


 


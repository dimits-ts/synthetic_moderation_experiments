% !TEX root = ../main.tex
%

\section{Related Work}


\subsection{Synthetic discussions}

\ac{LLM} agents talking with each other has been an active area of research outside the context of discussion simulation. The term “\ac{LLM} self-talk” is usually used in this case, a term adapted from “self-play” in \ac{RL} \citep{cheng2024selfplayingadversariallanguagegame}). For instance, researchers have experimented with using self-talk for reinforcing \acp{LLM} against jailbreaking \cite{liu2024largelanguagemodelsagents, cheng2024selfplayingadversariallanguagegame, zheng2024optimalllmalignmentsusing}, for \ac{LLM} alignment \cite{Bai2022ConstitutionalAH, collective_constitution}, and self-refinement in general \cite{Madaan2023SelfRefineIR, lambert2024} by pitting the model against itself. \citet{ulmer2024} give their \ac{LLM} agents distinct roles in a conversational setting and demonstrate that \ac{LLM} self-talk can occasionally produce high-quality, convincing discussions. These discussions can be used to further finetune the model.  \citet{abdelnabi_negotiations} show that \acp{LLM} can execute (to some extent) social strategies in discussions in order to achieve long-term goals. An example is a negotiation where an environmentalist \ac{LLM} agent may be stoking disagreement between other agents, in order to eventually sabotage the negotiations for the creation of a new factory.


\subsection{Replicating human behavior with LLMs}

Studies demonstrate that while \acp{LLM} can not fully replicate human behavior, they approximate it to a limited extent. \citet{hewitt2024predicting} recommend employing \acp{LLM}s in social science experiments for minority groups, particularly pilot studies, but highlight limitations including low variance, model bias, and challenges in encoding all participant details into prompts. \citet{park2024generativeagentsimulations1000} reveal that substituting \acp{SDB} with interview-based information enhances their authenticity. However, their approach relies on extensive human interviews and computational resources.

\acp{LLM} can also simulate human behavior within communities. \citet{park_simulacra} use a single \ac{LLM} with \ac{SDB} prompting to generate entire Reddit communities, producing synthetic discussions indistinguishable from real ones. \citet{Park2023GenerativeAI} create an interactive in-game world where \ac{LLM}-controlled \acp{NPC} engage with players, the environment, and each other, displaying complex social behavior like information sharing and event planning. However, they note that these agents tend to be “too agreeable”, likely due to alignment artifacts.

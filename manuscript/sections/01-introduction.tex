% !TEX root = ../main.tex
%

\section{Introduction}
\label{sec:introduction}


Research on moderation techniques is crucial for adapting to evolving online environments, but lags significantly behind current demands \cite{seering_self_moderation, make_reddit_great}. A major challenge lies in the substantial human effort required—both in researching and moderating discussions, which results in slow development and elevated costs for researchers and platforms alike. Many platforms overcome this by outsourcing moderation to volunteers or users through self-moderation mechanisms \cite{Matias2019TheCL, schaffner_community_guidelines}, while others turn to automation (based on simple \ac{ML} models), which is however not enough in practice \cite{horta_automated_moderation, schaffner_community_guidelines}.

\acfp{LLM} have shown promise in simulating human behavior in social studies \cite{park2024generativeagentsimulations1000, hewitt2024predicting, Park2023GenerativeAI}, as well as adversarial agents in text-based tasks \cite{cheng2024selfplayingadversariallanguagegame}. However, the extent to which they can authentically replicate human behavior remains uncertain. Additionally, no studies to our knowledge suggest and evaluate techniques with which these discussions can become more representative.

We propose a methodology for leveraging synthetic experiments performed exclusively by \acp{LLM} to initially bypass the need for human participation in experiments involving online moderation. We investigate the diversity of the produced discussions with regard to different prompts, turn-taking algorithms, \ac{LLM} architectures, and the addition of different roles and \acp{SDB} for the synthetic participants. Finally, we make available “SynDisco”, an open-source Python framework designed to create and assess synthetic discussions, as well as the \ac{VMD}; a publicly accessible dataset containing evaluated synthetic discussions. 